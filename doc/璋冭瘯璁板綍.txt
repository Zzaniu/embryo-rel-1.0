
Copyright(c) 2015-6-5 Shangwen Wu

内存调试记录
1.测试写校准过程时，计算MAX和MIN可行wrlvl_delay的值时，出错
	（1）在打印MC参数值时，比对PMON打印的MC信息，发现有两个寄存器的值不一致
	，偏移地址分别为0x50和寄存器0x140。继续跟踪发现，对于0x50寄存器，我在ddr_config函数中对ECC的设置为“没有使用ECC设备”,而PMON的设置为”不使用ECC“。而0x140寄存器，因为变量定义错误导致。
	（2）在源码中查看到PMON的配置项中CLEAR_HALF_CLK_SHIFT已经配置。但是在代码中的#idfef CLEAR_HALF_CLK_SHIFT代码快中却 并没有被执行！！！！

2.运行C环境时，出现xtlb fill重填异常
	（1）栈指针没有设置正确值，将sp指针指向正确的内存地址（start - 0x4000）后异常消失

3.在添加ns16550驱动模块时，链接器提示警告：mipsel-linux-ld: warning: section `.sbss' type changed to PROGBITS
	（1）最后定位到ns16550.h文件中，发现错误定义了一个全局变量。并发现如果定义了一个全局变量，但是并没有取初始化它，就会提示出以上警告，而如果进行了初始化哪怕是初始化为0，也不会提示以上警告

4.在main_loop函数中测试read接口从串口读取数据时，发现一旦输入数据超过read传入的count参数时，BIOS卡死
	（1）低级错误，termio_read函数中一个表示长度的i表量未初始化

5.尝试在.S汇编文件中，定义一个C语言的全局变量时，编译报出“unrecognized opcode”错误
	（1）PMON在包含这些头文件中使用_LOCORE宏定义编译汇编文件，导致C语言的语法的头文件信息在编译汇编文件时不会真正被包含，而仅在编译包含这些头文件的C文件中才会得到包含

6. 使用andi指令与上一个负数时，编译报“expression out of range”错
	（1）andi指令仅用于0-65535范围内的掩码值，对于更大的数，需要使用宏指令and生成更多指令


GMAC调试记录：
1.上位机没有收到网口驱动发送的报文，此时没有发送中断产生并且DMA描述符没有正常移动到下一个位置
	（1）最开始检查是否时DMA地址错误或者DMA映射出了问题，通过对比PMON发现，地址与embryo一致，并且cache操作页对报文发送似乎无影响。然后检查报文数据是否正确，以及描述符是否正确设置，均排除了以上问题。后通过访问寄存器发现dma报“DMA无法访问描述符”的错误，怀疑是这个导致的问题，于是对比PMON，发现将pmon的收发轮询函数synopGMAC_intr_handler函数注销后，也出现了与我们BIOS相同的错误，但是发送仍然能够正常使用，只是没有回收空闲发送描述符，导致最后synopGMAC_xmit_frames卡死在轮巡描述符位置。后发现上位机显示网络为100M，而此时还未添加PHY状态轮询功能，于是将gmac端配置为100M模式后，发现stmmac驱动成功发送了第一个ARP数据报文!
	（2）后续调试中发现了另外一个问题：第一次up网口经常出现无法发送报文的情况，，而必须再次up初始化网口后才能正常发送报文。第一次UP网口时，通过mdio访问phy寄存器，发现phy的状态寄存器提示link down的情况，而此时网口无法发送报文，故推测报文发送失败与PHY的链接状态有关。后偶然发现，每次链接状态的改变，需要先读一下状态寄存器清除某些PHY中缓存，以使MDIO状态就绪。实际操作中，发现第一次读取状态都是未链接，而第二读取PHY状态时均显示链接上。而此时仍然无法发送，故排除PHY链接的原因。
	（3）在调试过程中发现偶尔出现DMA描述符寄存器指针可以正常移动，但是上位机收不到数据的情况，对比PMON发现，对于88E1111型号的PHY处理与内核不同，代码在复位之前写入RGMII的1.9ns延时，将bios的此部分逻辑修改成PMON一致后，上述现象消失；此外还在PMON下做了对比实验，将PHY初始化修改为先复位在写入延时寄存器，发现PMON下无法进行通信了，但是描述符指针会向前移动，现象与我们的BIOS一致，进行软复位后此现象消失。后阅读88E1111手册得知，RGMII的收发延时需要通过软复位才能生效，PMON的这么做是对的。
	（4）关闭接收数据缓冲区的分配以及接收描述符轮询命令后，发现驱动能够稳定发送ARP报文数据，最终定位到分配rx的数据缓冲区地方，发现只要分配此段内存便会引起出错，故开始怀疑是否为内存越界问题，但是检查各个字段，发现没有出现变量异常修改的情况；最终定位到，只需要在分配rx描述符之后，分配rx数据缓冲区之前，加入任一条打印语句，便能稳定发送数据报文，还是怀疑可能是缓存问题。
	（5）尝试在进行描述符字段填充时，指针增加volatile防止没有真正写入到内存，但是仍然没有效果
	（6）通过对比正常和异常情况，发现出错的情况下，使用kesg1空间打印发送描述符的各个字段均为驱动正常设置的值，而使用kseg空间打印这些描述符发现开始几个位置的描述符出现全为0的情况，而正常情况下，kseg0与kseg1的描述符空间的值是一致的。
	（7）根据（6）发现的规律，我做了如下两个尝试：a，在异常发生的情况下，通过内存访问命令手动将最开始几个位置的描述符在kseg0空间的值修改成和在kseg1空间中一样的正常值；b，将dma一致性内存分配函数返回的kseg1地址故意修改成返回kseg0空间的地址（当然这么做是错误的）。通过以上两个尝试性修改，结果发现网口发送数据包正常。通过以上得出一个结论，gmac网口在进行描述符的访问时，其得到的值仿佛是从kseg0中取出的数据，而非实际内存空间（kseg1）中的数据，因为以上第二个实验中，kseg1中的描述符是未初始化的，而gmac也能正常发送数据。当然，如果gmac如果发现要进行DMA的描述符空间在cache中没有任何有效的缓存项（通过flush缓存可以做到），其也能正常工作。
	（8）在上述测试过程中，还发现在正常的情况（比如PMON下）通过kseg0读取描述符空间，将导致后续发送失败。这一点更加证明了：gmac在访问描述符时，如果对应的描述符在缓存中有对应的条目，并且缓存条目与实际内存中的值不一致时，gmac将访问描述符失败，从而导致数据发送失败，表现就是DMA控制器不会移动DMA描述符指针，除此之外没有任何错误。
	（9）GMAC发送数据报文，最理想的情况就是，在开始发送时，DMA描述符必须在缓存中没有对应的项。而我们板子故障原因就是因为DMA描述符在进行缓存一致性分配后（此时，该片空间被flush到了内存），在某个时刻被意外的加载到了cache中，而且被CPU意外修改成了其他的值，导致cache与内存中数据不一致。为了验证该猜想，在故障的情形下，通过kseg1地址，往描述符空间写入一个特定的值，然后通过kseg0地址回读，结果发现，kseg0回读的值不是我们刚写入的值，而对比正常的情况，回读的值与写入的值是一致的。说明在我们写入操作之前，对应的地址就已经在cachce中了，回读的时候读出的是之前cache中的老值，而非通过uncache方式写入的新值。
	（10）基本故障原因已经基本可以确认，然而引起该原因的代码却没有找到，表面上可以看出是接收数据缓冲分配的函数导致，然而具体跟踪到内存分配中某个具体的语句后发现，该语句与我们描述符的地址完全没有任何联系，无奈之下，只好先排除是整个cache操作的问题，于是将pmon的cache初始化还有flush操作的代码照搬到我们bios中，然而问题依然出现。
	（11）在排除了cache传惨以及flush函数奇怪的栈设置之后，偶然想到了编译器优化的问题，也基本只有编译选项与PMON不同，于是将编译选项增加了一些警告提示以及降低优化级别后，发送数据居然正常了！具体原因现在还没有找到，但是推测大概原因，可能是编译器优化导致某个位置意外访问了DMA描述符空间，或许是因为批量读取也可能是某些操作因为优化而被移动了访问先后的顺序。


SATA硬盘调试记录
1.ahci接口发送sata命令时出现命令超时
	（1）引起上述问题有两种情况，当命令格式本身不正确时，会出现命令发射超时的现象，一般在编写驱动代码前期出现，主要是几个函数对命令的封装出现了低级错误导致。
	（2）第二种情况为偶发现象，但是有明显的错误规律。在后期加载硬盘里的内核时固定出现，出错现象是当传输大量数据时，ahci模块报命令发射超时错误，从而导致加载失败，并且，ata_read/ata_write几个调试命令也会引起该问题。于是使用该命令并将每次读取的块数增加或者减小来进行测试，测试时发现，将块数增大到某一临界值时，将出现命令超时，反之，当访问块数小到一定程度时，超时现象消失，同时在临界值附近，每次测试的结果也不稳定，偶尔超时偶尔正常。于是怀疑底层IO对于大数据量支持存在问题，后跟踪到最底层的命令发射函数ahci_device_data_xfer中，该函数命令发射后，将会等待一定时间判断是否发射完成，而该时间是一个固定值，并该默认等待时间值较小，于是猜测对大数量操作时花费时间增大，目前的超时时间过小导致命令函数传输过程中超时判断就已经生效，于是，将该超时时间修改到足够大后，问题解决。

tftp调试记录
1.使用tftp下载大文件时，出现内存泄漏
	（1）最开始思考问题的时候，都不确定当时是不是内存泄漏，因为当时判断内存泄漏的依据仅仅是观察到系统会偶尔申请的新的内
存，理论上来说，对于一个命令或者代码的循环执行，只要中间的代码对于内存的分配与释放操作得当，那么是肯定不会新分配内存空间的，
tftp不断的读取远端文件其实就是这样一个循环读取固定数据包的过程，只要中间对任何新分配的内存都进行了释放操作，那么应当不会产生
新分配内存的情况。但是，测试条件中有个不确定的因素就是当时上位机（WINDOWS系统）会时不时发送一些奇奇怪怪的无用数据包，这些数
据包即使不是发送到本机，但还是会被embryo的协议栈接收（虽然最后会被丢弃），如果当时数据通信较密集时（比如正在tftp大文件），这
些不被关心的数据包很可能不会被立即得到处理而是将其插入到网络接收队列中，从而会不断分配新的内存到接收队列而暂时不会得到释放，
这样一来只要通信压力一直在缓慢增大，那么这种分配新内存的情况也将一直持续下去。这种情况也比较好复现，在上位机通过一个网络调试
工具不断地发送udp报文，发送的压力要大于embryo接收处理的能力，将很容易出现不断分配新内存的现象。当然，这属于正常现象而不是之
前怀疑的内存泄漏。那如何证明到底是不是内存泄漏引起的反复分配新内存操作呢？最要的一点，必须严格排除通信压力的影响，这样就必须
去掉上位机发送的多余数据包，因为我们知道，tftp是基于“请求-响应”机制上的，那么单纯的tftp传输在目前的局域网环境下就绝不会出
现embryo来不及处理的情况，因此只要保证上位机仅发送我们需要的tftp报文，避免发送其他杂包干扰的情况下，就能够达到一种比较稳定可预测的命令循环执行的状态。在这里我将上位机换成较为纯净的linux发行版系统（不会胡乱发送一堆莫名其妙的报文）再进行测试，然后几轮tftp过后仍然出现了新分配内存的现象，于是，基本可以认为tftp的传输过程中确实存在内存泄漏。
	（2）首先打算排除tftp协议的影响，于是使用上位机的udp调试工具与enbryo来回进行不断的udp收发测试，测试过程中也能够观察到反复分配内存的情况，但是这种测试对于上位机调试工具的发送压力程序不太好拿捏，因为发送过快所引起的反复新分配内存不应当被认为是错误。这样就不太好明确分配内存现象是由于udp协议栈的内存泄漏问题还是调试工具数据发送过快引起的网络拥堵。
	（3）为了确定引起内存泄漏的大体区域，将embryo的接收端暂时关闭，而仅仅打开发送端，并使用测试命令不断发送udp报文到上位机，结果发现，将发送提速到embryo的极限值，并且进行了长时间测试，都没有出现任何新分配内存的现象，因此可以断定问题出现在embryo的接收方向上。
	（4）在确定问题出现在接收方向后，通过代码打印跟踪到了新分配内存的具体代码位置，可是这个位置并不一定就是泄漏位置，并
且通过代码检查发现协议栈中并无出现分配的内存未释放的情况。
	（5）为了进一步缩小泄漏内存的可能区域，在上位机端编写了一个不断发送ARP请求报文的测试程序，并对embryo进行不断的ARP请求，长时间测试发现，embryo内存端并无出现泄漏问题，于是基本排除以太网层到ARP层之间引起泄漏的可能性（原本打算继续排除IP层区域，但是上位机需要额外下载一个fping的发包工具进行测试，于是索性作罢了）。
	（6）同时还发现另一个现象就是，使用网络调试工具发送非本机端口的UDP数据报文时，也没有出现内存泄漏的情况，因此，UDP接收这一层也基本可以排除出问题的可能性。
	（7）现在基本可以认为问题出现在协议层之外的接收处理中，那么很可能是socket接收到应用层这一区域存在问题，可是通读代码并未发现有新分配内存且没有释放情况。
	（8）通过上位机抓包时发现一个规律：tftp在传输过程中偶尔会出现莫名其妙的重传，而且只要传输过程中出现新分配内存的情况
就必定会引起tftp重传。而更重要的是，对于每次重传，两个重复的报文都被embryo的udp层检测并且将其插入到socket接收缓冲区，可是
tftp应用层却并没打印tftp报文重复的提示信息。很明显，从系统层到应用层过渡的位置存在某种错误将某个报文不小心丢弃并且并没有对齐
进行释放，从而导致内存泄漏。此外，上面还提到一个问题就是为什么会引起重传？按道理来说，目前局域网环境下应该不存在报文丢失或者
embryo处理不及时的情况（因为tftp服务器的超时时间一般有1秒左右），至于为什么会引起重传，将在下一个问题中进行分析。现在来看第
一个问题，从系统层到应用层过渡的地方一般有这样几个函数soreceive、recvit、soo_read、sys_read这几个函数，主要逻辑都集中在soreceive函数中完成，通过加入调试信息发现，当由于某种原因（后面提到）发生重传时，两个重复报文将在很短时间内一起被驱动层加入到udp接收队列，并由udp层加入到绑定了该udp报文端口的socket接收缓冲区中，跟踪发现当soreceive函数将socket缓冲区队首的数据报文（第一个引起重传的报文）出队后，其后的队列（第二个重复报文）的元素指针变成了NULL，就是后面的报文丢失了。后发现代码中出现的低级错误导致队首元素出队后没有及时保存后面的队列元素，从而引起数据丢失，并最终引起了tftp通信时触发的内存泄漏问题。

2.tftp传输速度很慢仅有几十Kbs（PMON tftp传输速度的几十分之一）
	（1）当传输小量数据时，并无异常情况出现，但是当文件大小超过一定程度时，传输会出现明显的卡顿，而通过上位机抓包发现，
传输过程中偶尔会出现重传，每次重传将卡顿超过1秒左右的时间。通过修复前面提到的内存泄漏问题后，造成重传的那个数据包最终还是会
被tftp接收到并在客户端程序中提示收到重复报文，也就是说，某种情况下收到某个tftp包后，花了很长时间才得到处理并发回给tftp服务端一个ack，从而导致服务端认为这个包超时了进而发送一个重复的报文。
	（2）对于为什么会引起重传，有两个可能性，一个可能是因为设备驱动层早已经将包接收到了，但是socket却很久才从网络协议层将数据取走，另一个可能是因为设备驱动层本身就很久才收到数据包。为了验证第一个问题，需要在协议层中间加入调试信息，但是加入打印
信息的过程中发现，凡是只要在调用tftp发送函数之后、接收函数之前插入任何打印信息，那么反而会造成异常现象的消失，难道是某些代码
涉及到时序问题？这给调试带来不小的麻烦，后来为了复现问题的同时还能得到有用的调试线索，在上述临界的区域中仅对一个计数值进行累
加，而在临界区之外将这个计数信息打印出来，从而避免打印延时对处理过程造成的时序影响。后发现在异常情况下，从网卡接收到新数据到
协议层、应用层取走这个数据之间并没有花费太多时间，而网卡本身检测到新数据却花费了相当长的时间，于是，调试重点可能在于stmmac网
口驱动对于接收数据方向的处理。
	（3）初步怀疑可能是网口驱动偶尔探测不到接收中断，为了验证这一猜测，将上位机tftp服务器的重传功能关闭，并且排除上位机
发送的其他杂包干扰后，embryo会出现接收死等的情况（之所以死等是因为目前embryo还未加入超时功能），结合之前的现象来说，异常发生时，实际上DMA空间中已经接收并保存了新到的报文（因为能够检测到重复报文），但是不知什么原因导致stmmac驱动没有探测到新数据报文产生的接收完成中断。
	（4）目前，并没有找到代码上的设计缺陷，而是通过探测另一个与接收相关的中断——“早期接收中断”标志位来确定是否有新数
据到达，从而回避了问题，但是并不确定会有什么潜在问题。



